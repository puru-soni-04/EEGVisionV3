{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('qtAgg')\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mne.preprocessing import ICA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=18, n_times=16875\n",
      "    Range : 0 ... 16874 =      0.000 ...   134.992 secs\n",
      "Ready.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Filter length: 413 samples (3.304 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>2 misc, 16 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>1.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>62.50 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:02:15 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 18 x 16875 (135.0 s), ~2.3 MB, data loaded>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'../Data/Pre Processed Data/Cleaned/cleaned_data_2023-03-24_11-25-42.csv')\n",
    "\n",
    "CHANNEL_NAMES = data.columns.values.tolist()\n",
    "CHANNEL_TYPES = ['misc', 'misc'] + ['eeg']*16\n",
    "SAMPLING_RATE = 125\n",
    "\n",
    "info = mne.create_info(ch_names=CHANNEL_NAMES, ch_types=CHANNEL_TYPES, sfreq=SAMPLING_RATE)\n",
    "\n",
    "raw = mne.io.RawArray(data=data.values.T, info=info)\n",
    "raw.filter(1, None)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 3024x1702 with 4 Axes>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.application:Exception in callback functools.partial(<function Kernel.enter_eventloop.<locals>.advance_eventloop at 0x16ac1e5f0>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/purusoni/miniconda3/envs/EEGVision/lib/python3.10/site-packages/tornado/ioloop.py\", line 740, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/purusoni/miniconda3/envs/EEGVision/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 455, in advance_eventloop\n",
      "    eventloop(self)\n",
      "  File \"/Users/purusoni/miniconda3/envs/EEGVision/lib/python3.10/site-packages/ipykernel/eventloops.py\", line 141, in loop_qt5\n",
      "    return loop_qt4(kernel)\n",
      "  File \"/Users/purusoni/miniconda3/envs/EEGVision/lib/python3.10/site-packages/ipykernel/eventloops.py\", line 121, in loop_qt4\n",
      "    _notify_stream_qt(kernel, kernel.shell_stream)\n",
      "  File \"/Users/purusoni/miniconda3/envs/EEGVision/lib/python3.10/site-packages/ipykernel/eventloops.py\", line 39, in _notify_stream_qt\n",
      "    notifier = QtCore.QSocketNotifier(fd, QtCore.QSocketNotifier.Read, kernel.app)\n",
      "AttributeError: type object 'QSocketNotifier' has no attribute 'Read'\n"
     ]
    }
   ],
   "source": [
    "# Plot the raw data\n",
    "raw.plot(scalings='auto', title='Data from arrays', show=True, block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 16 channels (please be patient, this may take a while)\n",
      "Selecting by number: 16 components\n",
      "Fitting ICA took 6.9s.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (16 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 16 PCA components\n",
      "Channels marked as bad:\n",
      "['EXG Channel 4 (P7)', 'EXG Channel 2 (C3)', 'EXG Channel 14 (P3)']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ica \u001b[39m=\u001b[39m ICA(n_components\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m97\u001b[39m)\u001b[39m.\u001b[39mfit(raw)\n\u001b[1;32m      2\u001b[0m raw_clean \u001b[39m=\u001b[39m ica\u001b[39m.\u001b[39mapply(raw)\n\u001b[0;32m----> 3\u001b[0m raw_clean\u001b[39m.\u001b[39;49mplot(scalings\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m, title\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mData from arrays\u001b[39;49m\u001b[39m'\u001b[39;49m, show\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, block\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/mne/io/base.py:1530\u001b[0m, in \u001b[0;36mBaseRaw.plot\u001b[0;34m(self, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[39m@copy_function_doc_to_method_doc\u001b[39m(plot_raw)\n\u001b[1;32m   1520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39mself\u001b[39m, events\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, duration\u001b[39m=\u001b[39m\u001b[39m10.0\u001b[39m, start\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, n_channels\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,\n\u001b[1;32m   1521\u001b[0m          bgcolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, bad_color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlightgray\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m          precompute\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, use_opengl\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, theme\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1529\u001b[0m          overview_mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1530\u001b[0m     \u001b[39mreturn\u001b[39;00m plot_raw(\u001b[39mself\u001b[39;49m, events, duration, start, n_channels, bgcolor,\n\u001b[1;32m   1531\u001b[0m                     color, bad_color, event_color, scalings, remove_dc,\n\u001b[1;32m   1532\u001b[0m                     order, show_options, title, show, block, highpass,\n\u001b[1;32m   1533\u001b[0m                     lowpass, filtorder, clipping, show_first_samp,\n\u001b[1;32m   1534\u001b[0m                     proj, group_by, butterfly, decim, noise_cov\u001b[39m=\u001b[39;49mnoise_cov,\n\u001b[1;32m   1535\u001b[0m                     event_id\u001b[39m=\u001b[39;49mevent_id, show_scrollbars\u001b[39m=\u001b[39;49mshow_scrollbars,\n\u001b[1;32m   1536\u001b[0m                     show_scalebars\u001b[39m=\u001b[39;49mshow_scalebars, time_format\u001b[39m=\u001b[39;49mtime_format,\n\u001b[1;32m   1537\u001b[0m                     precompute\u001b[39m=\u001b[39;49mprecompute, use_opengl\u001b[39m=\u001b[39;49muse_opengl,\n\u001b[1;32m   1538\u001b[0m                     theme\u001b[39m=\u001b[39;49mtheme, overview_mode\u001b[39m=\u001b[39;49moverview_mode,\n\u001b[1;32m   1539\u001b[0m                     verbose\u001b[39m=\u001b[39;49mverbose)\n",
      "File \u001b[0;32m<decorator-gen-157>:12\u001b[0m, in \u001b[0;36mplot_raw\u001b[0;34m(raw, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/mne/viz/raw.py:359\u001b[0m, in \u001b[0;36mplot_raw\u001b[0;34m(raw, events, duration, start, n_channels, bgcolor, color, bad_color, event_color, scalings, remove_dc, order, show_options, title, show, block, highpass, lowpass, filtorder, clipping, show_first_samp, proj, group_by, butterfly, decim, noise_cov, event_id, show_scrollbars, show_scalebars, time_format, precompute, use_opengl, theme, overview_mode, verbose)\u001b[0m\n\u001b[1;32m    306\u001b[0m precompute \u001b[39m=\u001b[39m _handle_precompute(precompute)\n\u001b[1;32m    307\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(inst\u001b[39m=\u001b[39mraw,\n\u001b[1;32m    308\u001b[0m               info\u001b[39m=\u001b[39minfo,\n\u001b[1;32m    309\u001b[0m               \u001b[39m# channels and channel order\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m               overview_mode\u001b[39m=\u001b[39moverview_mode,\n\u001b[1;32m    357\u001b[0m               )\n\u001b[0;32m--> 359\u001b[0m fig \u001b[39m=\u001b[39m _get_browser(show\u001b[39m=\u001b[39;49mshow, block\u001b[39m=\u001b[39;49mblock, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    361\u001b[0m \u001b[39mreturn\u001b[39;00m fig\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/mne/viz/_figure.py:662\u001b[0m, in \u001b[0;36m_get_browser\u001b[0;34m(show, block, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Initialize Browser\u001b[39;00m\n\u001b[1;32m    661\u001b[0m fig \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39m_init_browser(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 662\u001b[0m _show_browser(show\u001b[39m=\u001b[39;49mshow, block\u001b[39m=\u001b[39;49mblock, fig\u001b[39m=\u001b[39;49mfig)\n\u001b[1;32m    664\u001b[0m \u001b[39mreturn\u001b[39;00m fig\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/mne/viz/utils.py:161\u001b[0m, in \u001b[0;36m_show_browser\u001b[0;34m(show, block, fig, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     plt_show(show, block\u001b[39m=\u001b[39;49mblock, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mqtpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mQtWidgets\u001b[39;00m \u001b[39mimport\u001b[39;00m QApplication\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/mne/viz/utils.py:137\u001b[0m, in \u001b[0;36mplt_show\u001b[0;34m(show, fig, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     backend \u001b[39m=\u001b[39m get_backend()\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m show \u001b[39mand\u001b[39;00m backend \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39magg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     (fig \u001b[39mor\u001b[39;49;00m plt)\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/matplotlib/backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[0;34m(cls, block)\u001b[0m\n\u001b[1;32m   3618\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[1;32m   3619\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m-> 3620\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/matplotlib/backends/backend_qt.py:604\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    602\u001b[0m qapp \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQApplication\u001b[39m.\u001b[39minstance()\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m qapp:\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mwith\u001b[39;00m _maybe_allow_interrupt(qapp):\n\u001b[1;32m    605\u001b[0m         qt_compat\u001b[39m.\u001b[39m_exec(qapp)\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    143\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/EEGVision/lib/python3.10/site-packages/matplotlib/backends/qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[0;34m(qapp)\u001b[0m\n\u001b[1;32m    243\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ica = ICA(n_components=16, random_state=97).fit(raw)\n",
    "raw_clean = ica.apply(raw)\n",
    "raw_clean.plot(scalings='auto', title='Data from arrays', show=True, block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
